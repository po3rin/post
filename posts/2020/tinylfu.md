---
title: TinyLFU の論文を読んだので概要を紹介する。
cover: ../../img/tinylfu-cover.jpeg
date: 2020/07/17
id: tinylfu
description: TinyLFUが提案されている論文を読んでみました
draft: true
tags:
    - Go
    - Computer Science
---

## Overview

最近、[Database Internals](https://www.amazon.co.jp/dp/B07XW76VHZ/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1) を読んでいて ***TinyLFU*** に興味を持ったのですが、Database Internals ではTinyLFUの詳細が書かれていなかったので、TinyLFUが提案されている論文を読んでみました。その内容をザックリ解説してみようと思います。

論文はこちらです。
[TinyLFU: A Highly Efficient Cache Admission Policy](https://dgraph.io/blog/refs/TinyLFU%20-%20A%20Highly%20Efficient%20Cache%20Admission%20Policy.pdf)

## TinyLFU 概要

***TinyLFU*** は頻度ベースのキャッシュアドミッションポリシーを使用し、キャッシュヒット率を高めると同時に、軽量でハイパフォーマンスに設計されたアルゴリズムです。

## キャッシュで利用される基本的な置換ポリシー

キャッシュが一杯になったとき、***置換ポリシー*** に基づき、新たなアイテムを格納するためにどのアイテムを追い出すかを選択します。あるアイテムが他のアイテムよりもアクセスされる確率が高い場合、キャッシュヒット率をあげるために、アクセスされる確率の高いアイテムを置いておきたい訳です。

その為に、キャッシュにはアイテムとは別に、どのアイテムを選別するかを決定するためのメタデータを保持し、計算によってそれを求める必要があります。TinyLFUの前に基本的な置換ポリシーをみていきましょう。

### LFU

LFU(Least Frequency Used)は文字通り、最も頻繁に使用されるアイテムをキャッシュに残していく戦略です。
データアクセスパターンの確率分布が時間の経過とともに一定である場合は最も頻繁に使用されるものが最も高いキャッシュヒット率をもたらします。

一方でLFUには2つ問題があります。

* 内部に大規模で複雑なメタデータを維持する必要がある
* 実戦のほとんどではアクセス頻度は時間の経過とともに変化する

１つ目については全てのアイテムに対するアクセス回数、時間を保持する必要があります。さらに厳密にやるなら今キャッシュに保持していないアイテムのメタデータも保持する必要があります(Perfect LFU)。２つ目に関しては例えば、今日アクセス頻度の高かった動画が、明日人気であるとは限らないのでキャッシュに入れておく意味が薄れてしまいます。

### LRU

LFUの代わりとして検討できるのが時間的局所性を利用するLRU(Least Recently Used)です。最近使ったアイテムは今後も使う可能性が高いだろうと判断し、最も古いアイテムをキャッシュから削除する戦略です。LFUよりもかなりシンプルな実装になり、LFUが対応困難だった時間経過にも対応出来ます。しかし、LRUはLFUよりも多くのキャッシュサイズを必要とします。

## TinyLFU

TinyLFU のアーキテクチャは下記。ここでは、Eviction Policy が Cache Victimを選択し、TinyLFU が Cache Victim を新しいアイテムに置き換えることでヒット率の向上が期待できるかどうかを判定します。 下記のアーキテクチャのようにMain Cacheの前段階としてどのアイテムを挿入するかを決定します。

![tinylfu](../../img/tinylfu-archi.png)

こうすることで、TinyLFUにサイズの大きい統計情報の管理を託すことができます。一方で実戦ではTinyLFUに格納する統計情報が大きくなってしまうので、TinyLFUではこれらを近似して利用します。

TinyLFUのアーキテクチャで利用されているテクニックを詳しくみていきましょう。

### Approximate Counting

TinyLFU の重要な要素である Approximate Counting を考えていきます。これはどのようにアクセス頻度を近似するかを提案します。色んな方法がありますが、その中で TinyLFU の基礎となる ***Bloom Filter*** と ***Counting Bloom FIlter*** を紹介していきます。

#### Bloom Filter

空間効率の良い確率的データ構造であり、要素が集合のメンバーであるかどうかのテストに使われます。偽陽性（false positive）による誤検出の可能性があるが、偽陰性（false negative）がないのが特徴です。

Bloom Filter は簡単に説明すると k個のハッシュ関数に対応する配列(論文の文脈ではこれをapproximation sketches: 近似スケッチと呼んでいる)のインデックスにビットを立てていく。要素が集合に存在するかを確認したいときはその要素もハッシュ関数にかけて対象Bitが全て立っているかを確認する。下記の例では```k = 3```で集合```{"a", "b", "c"}```に対し、要素 ```w``` があるかを判定している例。```w```は1箇所Bitが立っていないので、集合に```w```は無いと断定できる。
k 個のハッシュ関数を利用しており、それぞれがキー値を配列位置のいずれかにマッピングする。

![tinylfu imaga](../../img/bloomfilter.png)

これの強力なところは、データ自体を格納する必要がない為、データ効率が格段に高く、要素数に関わらず```O(k)```時間で集合内に要素が無いことを確定できる。すごい。

過去にGoでBloom Filterを実装したことがあるのでもし良ければ参考に!
[Go bloomfilter package](https://github.com/po3rin/go_playground/tree/master/bloomfilter)


#### Counting Bloom Filter

Bloom Filter では要素を削除することが出来ない。その為、Filterの要素をBitではなく ***nビットのカウンタに拡張している***。要素の追加は各配列要素のインクリメントになり、削除する場合、対応する配列要素のカウンタをデクリメントすればいい。これの問題は要素数が大きすぎるとカウンタがオーバーフローする可能性があります。

![tinylfu imaga](../../img/countingbloomfilter.png)

### Freshness Mechanism

TinyLFUの論文ではグローバル・カウンタ```S```もインクリメントしていき、このカウンタSの値がサンプルサイズ(W)に達すると、Sと近似スケッチのすべてのカウンタを2で割りる```リセット法```を提案しています。リセット直後は、Sもrefleshされ、```S = W /2```になります。

![doorkeeper](../../img/tinylfu-fresh.png)

TinyLFUの論文ではリセット法を用いることで、スペースを増やすことなく近似スケッチの精度を向上させることができます。

この操作の欠点は、頻度は低いですが、近似スケッチ内のすべてのカウンタを調べて2で除算する操作です。しかし、シフトレジスタを使用することで、2による除算をハードウェア上で効率的に実装することができます。同様に、シフトおよびマスク演算により、複数のカウンタに対して一度にこの演算を実行することができます。

原文では割り算による切り捨て誤差の議論がありますが割愛します。

### Space Reduction

TinyLFUの論文で検討されているDoorkeeperをみていきます。

<!--
#### Small Counters

頻度ヒストグラムは、キャッシュ内の全てのアイテムの正確なランキングを決定する必要はありません。さらに、サイズCのキャッシュを考えた時に、アクセスされているアイテムの総数がＣよりも大きいという合理的な仮定の下で、サイズCのキャッシュではアクセス頻度が```１／C ```以上である全てのアイテムはキャッシュに属します。したがって，与えられたサンプルサイズ ```W``` に対して，カウンタを ```W /C``` で安全にキャッピングすることができます。 -->

#### Doorkeeper

TinyLFU では ```Approximate Counting``` スキームのカウンタのサイズをさらに小さくするために、頻度の低いアイテムに複数ビットのカウンタを割り当てないようにする ***Doorkeeper*** 機構を提案しています。

Doorkeeperは、```Approximate Counting``` スキームの前に配置された普通の ***Bloom Filter*** として使って実装されます。アイテムが到着すると、まずそのアイテムが Doorkeeper に含まれているかどうかを Bloom Filter でチェックし。Doorkeeper に含まれていない場合は Doorkeeper に挿入され、そうでない場合は次の ```main structure``` に挿入される。アイテムを問い合わせる際には、Doorkeeper と```main structure```の両方を使用します。下記は基本的なTinyLFUのアーキテクチャになります。

![doorkeeper](../../img/bfbefore.png)

つまり、Doorkeeper にアイテムが含まれている場合、TinyLFU はそのアイテムの頻度を```Approximate Counting``` スキームでの推定値に1を足した値として推定する。それ以外の場合は、```Approximate Counting``` スキームからの推定値のみを返します。リセット操作を行う際には、メイン構成の全てのカウンタを半減させることに加えて、```Doorkeeper``` の値をクリアします。

メモリ的には、Doorkeeper は追加のスペースを必要としますが、```Approximate Counting``` スキームに挿入されるユニークなアイテムの量を制限するため、利用するメモリを小さくすることができます。特に、ほとんどの低頻度アイテムには、```Doorkeeper``` では1ビットのカウンタしか割り当てられていません。

#### W-TinyLFU

実は、理論的な観点からはTinyLFU は LRU よりも競合率が悪いという報告があります。それを改善する為に、W-TinyLFUという機構が提案されています。W-TinyLFUはアドミッションポリシーを採用したメインキャッシュとアドミッションフィルタを持たないウィンドウキャッシュの 2 つのキャッシュ領域から構成されます。

![doorkeeper](../../img/wtiny.png)

キャッシュミスが発生するたびに、アクセスされたアイテムはウィンドウキャッシュに挿入される。ウィンドウキャッシュのVictimは、その頻度推定値がメインキャッシュのVictimよりも高いか低いかに応じて、メインキャッシュに挿入すべきかどうかを決定するためにTinyLFUに渡さます。

このアーキテクチャは汎用的であり、ウィンドウキャッシュとメインキャッシュには任意の退避ポリシーを選択でき、相対的なサイズも任意です。しかし、このアーキテクチャにおけるウィンドウキャッシュの目的は、最近アクセスされたアイテムを保持することなので、この論文では ***ウィンドウキャッシュの退避ポリシーをLRUに設定しています***。ウィンドウキャッシュでVictim発生するとDoorKeeperに送られてフィルタリングされ、フィルタリング後は大きな ***Segmented LRU*** キャッシュに要素が格納されます。

***Segmented LRU（SLRU）*** は、LRUを改良したもので、2回以上ヒットしたレコードと1回ヒットしたレコードを別々に格納することで、短期的にキャッシュされた要素の頻度が高いものを区別できるようにしたものです。SLRUは下の図のように、***Probation*** と ***Protected*** と呼ばれる2つのLRUで構成されます。

![doorkeeper](../../img/slru.png)

Probation には常に新しいレコードが挿入され、Probation のレコードが再度アクセスされると、Protection に移動されます。Protectionが一杯になると、Probationに戻されます。W-TinyLFUでは、SLRUのスペースの80%がセクション Protection に割り当てられています。

#### まとめ

TinyLFUを紹介し、その拡張であるW-TinyLFUも紹介しました。僕がよく書くGoでは```ristretto```をいうキャッシュパッケージが内部でこの考え方を採用しているようです。

[![doorkeeper](../../img/ristretto.png)](https://github.com/dgraph-io/ristretto)

実戦での選択肢としてこういうコンピュータサイエンスの論文は趣味でどんどん追っていきたいと思います。
