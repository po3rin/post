---
title: LLMで作る検索データセット~検索エンジンオフライン評価の夢に向かって~
cover: img/gopher.png
date: 2023/12/18
id: m3-search-dataset
description: Go is a programming language
tags:
    - golang
    - markdown
draft: true
---

## Overview

エムスリーエンジニアリンググループ AI・機械学習チームでソフトウェアエンジニアをしている中村([po3rin](https://twitter.com/po3rin)) です。
今回はLLMで作る検索データセットを作る挑戦についてお話しします。

[:contents]

<!-- more -->

## 検索エンジンオフライン評価の課題と解決方針

検索エンジンを運用していると、辞書や、ベクトル検索、ランキングモデルのアップデートに伴い、オフライン評価をしたくなることがあります。

検索結果のランキングのオフライン評価を行う時のよくある方法として、ユーザーの行動ログ(クリックログ)などから「正解データ」を作成し、`nDCG`などの評価指標でオフライン評価をする方法があります。

もちろん、既存データセットを使う方法もありますが、ドメインによっては最適なデータセットではない可能性があります。例えば弊チームでは医療特化の検索エンジンを運用しているため、既存のデータセットよりも、ユーザーの行動ログからデータセットを作った方が評価したいドメインに近いデータセットが作れます。

しかし、ユーザーの行動ログからオフライン評価を行うのは下記のデメリットが挙げられます。

### Historical Biasが発生している可能性がある

正解データを旧ロジックにより生成しているため、旧ロジックの方が過大評価される可能性があります。特にランキングの評価にはポジションバイアスが含まれる可能性があるため、旧ロジックが上位に出したものほどクリックされるため、正解データとして最適なものとは限らなくなります。

### ユーザー行動内のノイズが発生している可能性がる

ユーザーは予期せぬ理由でクリックをおこなう可能性があるため、クリックデータをそのまま正解データとするとノイズが含まれてしまう可能性があります。

### 解決方針

ユーザーの行動ログからオフライン評価を行うのはラベルづけ済みのデータセットを作成しなくても良いというメリットがありますが、上記で挙げた理由により最適ではない可能性があります。

そこで、ユーザー行動にとらわれず、旧ロジックにも依存しないデータセットをあまり労力をかけずに生成するのが理想です。そこでLLMで検索データセットを生成し、それを評価に使えないかを検討してみました。

## LLMでデータセットを作成する実験

クエリに対するドキュメントの適合度を3段階で生成します。評価指標はnDCGを使う前提で作成し、2:高適合、1:部分適合、0:非適合とします。

まずは医療系のクエリをリストで取得します。弊チームの場合は医療系の検索クエリが十分なほど存在しているため、そちらから拝借します。

この医療系クエリを使って、それぞれ適合度の違う文章を考えてもらいます。

```py
import re
import json

from openai import OpenAI
client = OpenAI()

completion = client.chat.completions.create(
  model='gpt-4-1106-preview',
  messages=[
    {
        'role': 'system',
        'content': """
        「糖尿病」に関係のある記事タイトルと「糖尿病」に関係のない記事タイトルを複数作成し、「糖尿病」との関連度を0~2の3段階で付与してください。2が最も関連度が高いものとします。
        関連度0は「糖尿病」と全く関係のないタイトル、関連度1は直接の関連はないが部分的、または間接的に関係のあるタイトル、関連度2は「糖尿病」と直接関係のあるタイトルとします。
        結果は、以下のようなJSON形式で提出してください。
        
        {"title": "糖尿病と関連のある記事タイトル", "score": 2, "reason": "理由"}
        """
    }
  ]
)

result = completion.choices[0].message.content
print(result)
```

結果(JSONフォーマット済み)

```json
[
  {
    "title": "糖尿病治療の最新薬物療法",
    "score": 2,
    "reason": "糖尿病治療に直接関連する内容を扱っています。"
  },
  {
    "title": "血糖値のコントロールと食生活",
    "score": 2,
    "reason": "血糖値の管理は糖尿病管理において重要です。"
  },
  {
    "title": "健康的な食事のための5つのヒント",
    "score": 1,
    "reason": "健康的な食事は糖尿病予防や管理に役立つ可能性がありますが、直接的に糖尿病に言及しているわけではありません。"
  },
  {
    "title": "運動不足が招く様々な健康問題",
    "score": 1,
    "reason": "運動不足は糖尿病のリスク要因の一つですが、記事タイトルに直接的な言及はありません。"
  },
  {
    "title": "地球温暖化の影響と対策",
    "score": 0,
    "reason": "地球温暖化は糖尿病とは直接関連がありません。"
  },
  {
    "title": "インフルエンザの予防接種の効果",
    "score": 0,
    "reason": "インフルエンザの予防接種は糖尿病とは無関係なトピックです。"
  }
]
```

結果を見ると、実際に「糖尿病」と関連のあるものからないものまでが生成できています。これを関連度順に並べることができれば、良い検索エンジンと言えそうです。

LLMでオフライン評価用のデータセットを作成する希望が見えてきました。

## データセットサイズの決定

あとはクエリとドキュメント集合の組み合わせの数を幾つにするかです。大きすぎるとOpenAIのAPI呼び出し料金が無駄にかかってしまうため、なるべく小さい、かつ評価に十分なサンプル数が必要です。

t検定によるABテストで、Cohenのファイブエイティー慣習(有意水準5%、検出力80%)に従うことを前提とした場合、母集団効果量の見積りが必要ですが、今回は簡単のためにCohenによる効果量の大きさの基準を参考に「小さな効果量」目安である0.2を採用します。

https://www.mizumot.com/method/mizumoto-takeuchi.pdf

そうすると、有意水準5%、検出力80%、母集団効果量の下限を0.2(すなわち標準偏差の1/5に相当する差に対して検出力80%を保証する)とし、必要なサイズは199となります。詳しくは「情報アクセス評価方法論」の第6章「トピック数設計」を参考にすると良いでしょう。

## 生成したデータセットでterm検索とベクトル検索を評価してみる



